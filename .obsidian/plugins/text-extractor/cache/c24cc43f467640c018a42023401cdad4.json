{"path":"UnB/PE 2/pdfs/03 - regressão linear simples.pdf","text":"Universidade de Bras´ılia Instituto de Ciˆencias Exatas Departamento de Estat´ıstica Probabilidade e Estat´ıstica 2 1o semestre de 2020 Gustavo L. Gilardoni Regress˜ao Linear Simples 25 de Abril de 2022 0 Introdu¸c˜ao • Nas unidades anteriores estudamos sobre a rela¸c˜ao de uma vari´avel resposta com uma vari´avel qualitativa que podia tomar dois ou mais valores. Nesta unidade vamos estudar a rela¸c˜ao entre duas vari´aveis quantitativas. O caso mais simples • Durante muito tempo o ser humano procurava uma explica¸c˜ao mecanicista do mundo que o rodeia. A rela¸c˜ao entre coisas ou vari´aveis era determinista. Se soltarmos um objeto de massa m de uma altura h ele vai chegar ao solo com a velocidade v em exatamente o tempo t. • No s´eculo XX toma muita for¸ca uma vis˜ao do mundo onde acontecem coisas ao acaso, primeiro nas ciˆencias ditas duras (f´ısica quˆantica, por exemplo) e posterior- mente nas outras ´areas. Exemplo 1. Exemplo 2. 1 O Modelo • Dadas duas vari´aveis aleat´orias Y e X, pensamos modelar o valor esperado condi- cional de Y dado que X = x. Dessa forma escrevemos E(Y | X = x) = g(x) para alguma fun¸c˜ao g. • O erro ϵ = Y − g(x) ´e uma vari´avel aleat´oria tal que E(ϵ | X = x) = 0 para todo x. • O caso mais simples, que vamos estudar nesta unidade, ocorre quando (i) a fun¸c˜ao g ´e linear em x e (ii) a variˆancia do erro n˜ao depende de x. Suponha que observamos a vari´avel resposta y1, . . . , yn para n individuos com valores x1, . . . , xn da covari´avel X. Assumimos que os valores de x1, . . . , xn s˜ao ﬁxados pelo experimentador ou, alternativamente, que toda a inferˆencia ser´a feita condicional a esses valores. De acordo `a discuss˜ao anterior o modelo ´e    E(yi|xi) = α + β xi Var(yi|xi) = σ2 i = 1, . . . , n 1 0.0 0.5 1.0 1.5 2.0−20002004006008001000 (a) distanciavelocidade 50 60 70 80 90405060708090100 (b) vestibularIRA Figura 1: (a) Distˆancia da Terra (em megaparsecs) e velocidade de recess˜ao (em km/s) para 24 nebulosas de gal´axias (dados coletados pelo astrˆonomo Edwin Hubble por volta de 1929); (a) notas de ingresso no vestibular e IRA durante o primeiro ano do curso para alunos de um curso de estat´ıstica. ou, equivalentemente, yi = α + β xi + ϵi (1) com os erros ϵi tais que    ϵ1, . . . , ϵn s˜ao independentes; E(ϵi) = 0 V ar(ϵi|xi) = σ2 i = 1, . . . , n . (2) sendo independentes e tais que E(ϵi) = 0 e Var(ϵi|xi) = σ2. Veja que o modelo tem trˆes parˆametros: α, β e σ2. 2 Os estimadores de m´ınimos quadrados Para ajustar uma reta de regress˜ao como as da Figura 1 podemos proceder da seguinte forma. Considere o vetor y = (y1, . . . , yn) em Rn. Nos queremos aproximar esse vetor por um outro da forma ˜y = (ˆα + ˆβx1, . . . , ˆα + ˆβxn) com ˆα e ˆβ escolhidos convenientemente. Uma possibilidade conveniente pode ser escolher ˆα e ˆβ de forma a minimizar a distˆancia euclidiana entre y e ˜y ou, o que ´e a mesma coisa, o quadrado da distˆancia d 2(y, ˜y) = h(ˆα, ˆβ) = n∑ i=1(yi − ˆα − ˆβ xi) 2 . 2 Derivando com respeito a ˆα e a ˆβ e igualando a zero, obtemos as assim chamadas equa¸c˜oes normais − 1 2 ∂ h ∂ ˆα = n∑ i=1 yi − n ˆα − ˆβ n∑ i=1 xi = 0 (3) − 1 2 ∂ h ∂ ˆβ = n∑ i=1 xi yi − ˆα n∑ i=1 xi − ˆβ n∑ i=1 x2 i = 0 . (4) Da equa¸c˜ao (3) obtemos que ˆα = ¯y − ˆβ ¯x (5) e substituindo em (4) obtemos ˆβ = ∑n i=1 xiyi − n ¯x ¯y ∑n i=1 x2 i − n ¯x2 = ∑n i=1(xi − ¯x) (yi − ¯y) ∑n i=1(xi − ¯x)2 . (6) Estes estimadores s˜ao chamados Estimadores de M´ınimos Quadrados e foram usados para ajustar as retas de regress˜ao na Figura 1. Falta achar um estimador para σ2. Veja que se α e β fossem conhecidos, poder´ıamos usar o estimador n−1 ∑n i=1 ϵ2 i = n−1 ∑n i=1(yi − α − β xi)2. Por´em, como os erros ϵi = yi−α−β xi n˜ao s˜ao conhecidos, podemos substituir pelos res´ıduos ei = yi− ˆα− ˆβ xi. Nesse caso, pode-se mostrar que o denominador correto para obter um estimador n˜ao-viesado de σ2 ´e (n − 2), de forma que ˆσ2 = 1 n − 2 n∑ i=1(yi − ˆα − ˆβ xi)2 = 1 n − 2 [ n∑ i=1(yi − ¯y)2 − ˆβ n∑ i=1(xi − ¯x) (yi − ¯y) ] . (7) Exemplo 1. (Continua¸c˜ao). Temos que ∑ i y2 i = 6511425, ∑ i yi = 8955, ∑2 i=1(yi − ¯y)2 = 651142 − (8955)2/24 = 3170091; ∑ i x2 i = 29.51779, ∑ i xi = 21.873, ∑ i(xi − ¯x)2 = 29.51779 − (21.873)2/24 = 9.583; ∑i xi yi = 12513.69, ∑i(xi − ¯x) (yi − ¯y) = 12513.69 − (8955)(21.873)/24 = 4352.332. Assim, os estimadores de m´ınimos quadra- dos s˜ao ˆβ = 4352.332/9.58329 = 454.16, ˆα = 373.125 − (454.16) (0.911) = −40.78 e ˆσ2 = (24 − 2)−1 [3170091 − (454.16) (4352.332)] = (232.9)2. Alternativamente, se as ob- serva¸c˜oes est˜ao guardadas sob os nomes x e y numa sess˜ao do R, basta executar o c´odigo “summary(lm(y∼1+x))” para obter esses resultados. 3 Propriedades dos estimadores e inferˆencia Assumindo somente (2) ´e poss´ıvel mostrar que os estimadores (6) e (5) s˜ao: • fun¸c˜oes lineares das observa¸c˜oes y1, . . . , yn; 3 • n˜ao-viesados. Por exemplo, como E(yi) = α + β xi + E(ϵi) = α + β xi e, da´ı, E(¯y) = α + β ¯x + E(¯ϵ) = α + β ¯x, E( ˆβ) = E { ∑n i=1(xi − ¯x) (yi − ¯y) ∑n i=1(xi − ¯x)2 } = ∑n i=1(xi − ¯x) E(yi − ¯y) ∑n i=1(xi − ¯x)2 = ∑n i=1(xi − ¯x) E(α + β xi − α − β ¯x) ∑n i=1(xi − ¯x)2 = β ∑n i=1(xi − ¯x) (xi − ¯x) ∑n i=1(xi − ¯x)2 = β . De forma semelhante, E(ˆα) = E(¯y − ˆβ ¯x) = E(¯y) − ¯x E( ˆβ) = α + β ¯x − β ¯x = α . • Dados quaisquer outros estimadores ˜α e ˜β que sejam tamb´em lineares e n˜ao- viesados, segue necessariamente que que Var(˜α) ≥ Var(ˆα) e Var( ˜β) ≥ Var( ˆβ). Esse resultado ´e conhecido como Teorema de Gauss-Markov. Fala-se que os esti- madores (6) e (5) s˜ao BLUE, pelo acrˆonimo em inglˆes de Best Linear Unbiased Estimators. Para se fazer inferˆencias tais como intervalos de conﬁan¸ca ou testes de hip´oteses sobre α e/ou β, ´e necess´ario achar as distribui¸c˜oes amostrais de ˆα e ˆβ, e para isso ´e necess´ario especiﬁcar a distribui¸c˜ao dos erros ϵi. Usualmente assume-se que eles s˜ao normalmente distribu´ıdos e, nesse caso, ´e poss´ıvel mostrar que: • Como ˆβ e ˆα s˜ao combina¸c˜oes lineares de Y1, . . . , Yn que s˜ao normalmente dis- tribu´ıdas, ent˜ao ˆβ e ˆη tamb´em s˜ao normalmente distribu´ıdas; • Vimos acima que E( ˆβ) = β e E(ˆα) = α; • Para caracterizar a distribui¸c˜ao dos estimadores, s´o falta calcular a variˆancia deles. ´E poss´ıvel mostrar que Var( ˆβ) = σ2 1 ∑n i=1(xi − ¯x)2 (8) e que Var(ˆα) = σ2 ∑n i=1 x2 i n ∑n i=1(xi − ¯x)2 ; (9) • O estimador ˆσ2 ´e independente tanto de ˆβ quanto de ˆα e (n − 2) ˆσ2 σ2 ∼ χ2 n−2 . • Portanto, usando o fato que a distribui¸c˜ao tm de Student com m graus de liberdade pode ser obtida como a ra¸c˜ao entre uma vari´avel aleat´oria Normal(0,1) e a ra´ız quadrada de uma χ2 m dividida pelos graus de liberdade m, segue que ˆβ − β ˆσ √ √ √ √ n∑ i=1(xi − ¯x)2 ∼ tn−2 (10) 4 e que ˆα − α ˆσ √ n ∑n i=1(xi − ¯x)2 ∑n i=1 x2 i ∼ tn−2 (11) • Esses dois resultados podem ser usados para construir intervalos de conﬁan¸ca para α e β e para se fazer testes sobre eles. Por exemplo, um IC de n´ıvel 100(1 − a)% para β ´e ˆβ ± t(n−2);a/2 ˆσ 1 √∑n i=1(xi − ¯x)2 e o correspondente intervalo para α ´e ˆα ± t(n−2);a/2 ˆσ √ ∑n i=1 x2 i n ∑n i=1(xi − ¯x)2 . • Para testar. por exemplo, a H0 que β = β0 contra a alternativa que β ̸= β0 ao n´ıvel de signiﬁcˆancia 100a%, rejeitamos a H0 se |tobs| = ∣ ∣ ∣ ∣ ∣ ∣ ˆβ − β0 ˆσ √ √ √ √ n∑ i=1(xi − ¯x)2 ∣ ∣ ∣ ∣ ∣ ∣ > t(n−2);a/2 . O p-valor desse teste ser´a 2 P (Tn−2 > |tobs|). Exemplo 1. (Continua¸c˜ao). Suponha que queremos testar se α = 0 ao n´ıvel de signi- ﬁcˆancia de 10%. Nesse caso calculamos tobs = ˆα ˆσ √ n ∑n i=1(xi − ¯x)2 ∑n i=1 x2 i . = −40.78 232.9 √ (24) 9.583 29.518 . = −0.489 O valor cr´ıtico ´e t22;0.05 . = 1.717 e portanto n˜ao rejeitamos a H0 que α = 0. O p- valor desse teste ´e 2 P (T22 > 0.489) = 0.629. Um IC com conﬁan¸ca 90% para α ´e −40.78 ± (1.717) (232.9) √ 29.518 (24) 9.583 . = (−184.05; 102.49) De forma an´aloga, um IC com conﬁan¸ca 90% para β ´e 454.16 ± (1.717) (232.9)/ √9.583 . = (324.96; 583.36). 4 A tabela ANOVA e o coeﬁciente R2 Quando estudamos an´alise da variˆancia a um fator, vimos uma decomposi¸c˜ao da varia- bilidade da resposta yij que basicamente era da forma SQtot = ∑ ij (yij − ¯y··) 2 = ∑ ij (yij − ˆyij) 2 + ∑ ij (ˆyij − ¯y··)) 2 = SQres + SQreg , onde ˆyij = ˆµi = ¯yi·. Comparando a SQreg com a SQres (ou, mais precisamente, os res- pectivos quadrados m´edios ap´os dividir pelos respectivos graus de liberdade), pod´ıamos testar a H0 que todas as m´edias dos tratamentos eram iguais. 5 Fonte de gl Soma de Quadrados Fobs varia¸c˜ao quadrados m´edios Regress˜ao 1 SQreg = ˆβ2 ∑ i(xi − ¯x)2 QMreg = SQreg 1 QMreg QMres Residuos n − 2 SQres = ∑ i(yi − ¯y)2 − ˆβ2 ∑ i(xi − ¯x)2 ˆσ2 = QMres = SQres n−2 Total n − 1 SQtot = ∑ i(yi − ¯y)2 Tabela 1: Tabela de An´alise da Variˆancia para testar a hip´otese β = 0. Existe uma decomposi¸c˜ao semelhante no caso da regress˜ao linear simples que pode ser usada para testar se β = 0. Deﬁna neste caso ˆyi = ˆα + ˆβxi e ei = yi − ˆyi e note das equa¸c˜oes (3) e (4) que ˆyi − ¯y = ˆβ (xi − ¯x). Logo, a identidade fundamental ´e SQtot = ∑ i (yi − ¯y) 2 = ∑ i (yi − ˆyi + ˆyi − ¯y) 2 = ∑ i (yi − ˆyi) 2 + ∑ i (ˆyi − ¯y) 2 = ∑ i e 2 i + ∑ i (ˆyi − ¯y) 2 = ∑ i e 2 i + ˆβ2 ∑ i (xi − ¯x) 2 = SQres + SQreg . Semelhante `a discuss˜ao feita na unidade de An´alise da Variˆancia, sob a hip´otese de normalidade dos erros ´e poss´ıvel mostrar que • SQres/σ2 segue uma distribui¸c˜ao χ2 com (n − 2) gl; • SQreg/σ2 segue, sob a H0 que β = 0, uma distribui¸c˜ao χ2 com 1 gl e • Sob H0, SQres e SQreg s˜ao independentes. Dessa forma, sabemos da deﬁni¸c˜ao da distribui¸c˜ao F de Snedecor que, sob H0, F = QMreg QMres = 1 σ2 SQreg/1 1 σ2 SQres/(n − 2) = (n − 2) SQreg SQres ´e um quociente entre duas vari´aveis aleat´orias independentes com distribui¸c˜ao χ2 divi- didas pelos respectivos graus de liberdade e segue, portanto, uma distribui¸c˜ao F1,(n−2) e o nosso teste rejeita H0 quando Fobs > F1−α;1,(n−2). Usualmente a informa¸c˜ao anterior ´e apresentada na tabela ANOVA 1. Note que o fato de rejeitar a H0 que β = 0 n˜ao diz necessariamente qual fra¸c˜ao da variabilidade de y ´e explicada pela introdu¸c˜ao da covari´avel (ou preditor) x. Em outras palavras, poderia ser que β ̸= 0 ´e relativamente pequeno, mas se a variˆancia do erro σ2 for tamb´em pequena, eventualmente a diferen¸ca entre β e 0 ser´a capturada pelo 6 Fonte de gl Soma de Quadrados Fobs varia¸c˜ao quadrados m´edios Distˆancia 1 1976602 1976602 36.4354 Residuos 22 1193489 54249.5 Total 23 3170091 Tabela 2: Tabela de An´alise da Variˆancia para o Exemplo 1. procedimento e rejeitaremos que β = 0. Para medir a propor¸c˜ao da variabilidade total dos yi (SQtot = ∑i(yi − ¯y)2) que ´e explicada pelo preditor x, usa-se o assim chamado coeﬁciente de determina¸c˜ao R2 = SQreg SQtot = 1 − SQres SQtot = ˆβ2 ∑ i(xi − ¯x)2 ∑i(yi − ¯y)2 Exemplo 1. (Continua¸c˜ao). Neste caso temos que SQtot = 3170091, ∑ i(xi − ¯x)2 . = 9.583 ˆβ . = 454.16 e portanto SQreg . = (454.16)2 (9.583) . = 1976602. Logo, SQres . = 3170091 − 1976602 . = 1193489 e R2 = 0.62, o que diz que 62% da variabilidade da velocidade ´e explicada introduzindo o preditor dist^ancia. Da tabela de an´alise da variˆancia 2 segue que ao n´ıvel de signiﬁcˆancia de 1% rejeitamos a hip´otese que β = 0 pois Fobs . = 36.435 > F0.01;1,22 . = 7.945. O p-valor do teste ´e P (F1,22 > 36.435) . = 4 × 10−6. Exerc´ıcio 1. Temos agora dois procedimentos para testar a H0 : β = 0 contra a alter- nativa Ha : β ̸= 0, um baseado no estat´ıstico tobs apresentado na Se¸c˜ao 3 e outro baseado no estat´ıstico Fobs da tabela ANOVA. Mostre que esses dois testes s˜ao equivalentes, isto ´e, que um rejeita se e somente se o outro tamb´em rejeita (dica: veriﬁque que Fobs = t2 obs). 5 Previs˜ao de valores “futuros” Existem dois problemas parecidos quando queremos saber o que acontecer´a com a vari´avel resposta correspondente a valores n˜ao observados na amostra. Por um lado, podemos es- tar interessados em estimar a m´edia µc dos valores da resposta y para todos os indiv´ıduos da popula¸c˜ao que tˆem um valor x = xc dado do preditor x. Por outro, poder´ıamos estar interessados em “estimar” o valor do yc para um ´unico indiv´ıduo da popula¸c˜ao que tem x = xc (as aspas em volta de “estimar” foram usadas aqu´ı pois yc n˜ao ´e um parˆametro ﬁxo, mas uma vari´avel aleat´oria, de forma que tecnicamente fala-se de previs˜ao ao inv´es de estima¸c˜ao; independente disso, os dois problemas s˜ao semelhantes). Abordamos primeiro o problema de estimar a m´edia µc. De acordo ao nosso modelo (1), µc = α + β xc. Como temos estimadores n˜ao-viesados para α e β dados nas equa¸c˜oes 7 (3) e (4), segue que o estimador ˆµc = ˆα + ˆβ xc ser´a tamb´em n˜ao-viesado para estimar µc. Para construir um IC ou fazer testes de hip´oteses sobre µc precisamos obter a dis- tribui¸c˜ao do estimador ˆµ, o que usualmente ´e feito sob o suposto de normalidade dos erros. Nesse caso, como ˆµc ´e uma combina¸c˜ao linear dos yi, segue que ˆµc ´e normalmente distribu´ıdo com m´edia µc e variˆancia Var(ˆµc) = Var(ˆα + ˆβ xc) = Var(¯y − ˆβ ¯x + ˆβ xc) = Var[ ˆβ (xc − ¯x) + ¯y] = (xc − ¯x) 2 Var( ˆβ) 2 + Var(¯y) + 2 (xc − ¯x) cov( ˆβ, ¯y) = σ2 { (xc − ¯x)2 ∑i(xi − ¯x)2 + 1 n } , (12) onde temos usado a equa¸c˜ao (8) e os fatos que (i) Var(¯y) = σ2/n e (ii) cov( ˆβ, ¯y) = 0 (veriﬁque!) Logo, t = ˆµc− µc√Var(ˆµc) √ (n−2) ˆσ2 σ2 /(n − 2) = ˆµc − µc ˆσ √ (xc−¯x)2 ∑ i(xi−¯x)2 + 1 n ∼ tn−2 . (13) Assim, por exemplo, um IC com conﬁan¸ca 100(1 − α)% para µc ser´a ˆµc ± tα/2;n−2 ˆσ √ (xc − ¯x)2 ∑ i(xi − ¯x)2 + 1 n . (14) Um problema diferente ´e “prever” um ´unico valor da resposta yc correspondente a um indiv´ıduo com x = xc. A semelhan¸ca com o caso anterior ´e que, se for desejada uma previs˜ao pontual, como E(yc) = α + β xc = µc e tamb´em E(ˆα + ˆβ xc) = ˆµc, a nossa previs˜ao “n˜ao-viesada” deveria ser ˆµc, o mesmo estimador que usamos acima para µc. Em outras palavras, a previs˜ao pontual de yc ´e igual ao estimador pontual de µc. Por´em, as coisas s˜ao diferentes quando queremos calcular por exemplo um intervalo de previs˜ao para yc. Veja que, intuitivamente, dever´ıamos ter consideravelmente mais incerteza ao prever um ´unico valor de yc que ao estimar a m´edia de todos os indiv´ıduos com x = xc. Como veremos a seguir, esse ´e efetivamente o caso. Para construir um intervalo de previs˜ao para yc, considere a diferen¸ca ec = yc − ˆµc = yc − ˆα − ˆβ xc . ´E claro que E(ec) = 0 e, como o nosso modelo postula que yc ´e independente de y1, . . . , yn e, portanto, tamb´em de ˆα e de ˆβ, segue que Var(ec) = Var(yc)+Var(ˆµc) = σ2+σ2 { (xc − ¯x)2 ∑i(xi − ¯x)2 + 1 n } = σ2 {1 + (xc − ¯x)2 ∑ i(xi − ¯x)2 + 1 n } (15) 8 (compare as equa¸c˜oes (12) e (15): o termo adicional 1 em (15) far´a que efetivamente a variˆancia (15) seja maior do que a (12)). Logo, um argumento semelhante ao que usamos para chegar `as equa¸c˜oes (10) ou (11) ou ainda (13) mostra que t = ˆµc−yc√Var(ec) √ (n−2) ˆσ2 σ2 /(n − 2) = ˆµc − yc ˆσ √ 1 + (xc−¯x)2 ∑ i(xi−¯x)2 + 1 n ∼ tn−2 . (16) Assim, um intervalo de previs˜ao com conﬁan¸ca 100(1 − α)% para yc ser´a ˆµc ± tα/2;n−2 ˆσ √ 1 + (xc − ¯x)2 ∑ i(xi − ¯x)2 + 1 n . (17) [novamente, compare as equa¸c˜oes (14) e (17)]. Exemplo 1. (Continua¸c˜ao). Suponha que estamos interessados em saber qual ´e a velocidade m´edia µc de nebulosas que est˜ao a 1.8mpc do sistema solar. A estimativa pontual para µc ser´a ˆµc . = −40.78 + (454.16) (1.8) . = 776.71km/s. De acordo `a equa¸c˜ao (14), um intervalo com conﬁan¸ca 90% para µc 776.71 ± (1.717) (232.9) √ (1.8 − 0.911)2 9.583 + 1 24 . = (276.16; 1277.26)km/s . J´a se o objetivo fosse prever a velocidade de uma ´unica nebulosa situada a 1.8mpc do sistema solar, a previs˜ao pontual ser´ıa a mesma (µc . = 776.71km/s), mas o intervalo de previs˜ao calculado de acordo `a equa¸c˜ao (17) ser´ıa 776.71 ± (1.717) (232.9) √ 1 + (1.8 − 0.911)2 9.583 + 1 24 . = (136.01; 1417.40)km/s , consideravelmente maior do que o IC para µc. 6 Diagn´ostico do modelo Existem basicamente dois supostos que foram feitos nas Se¸c˜oes anteriores. Primeiro, assumimos que todas as observa¸c˜oes seguem uma distribui¸c˜ao Normal. Segundo, assu- mimos que as variˆancias dos yi (ou dos ϵi) s˜ao todas iguais. Nas aplica¸c˜oes, usualmente queremos checar se os dados suportam esses supostos. O primeiro suposto (Var(yi) = σ2) ´e chamado de homocedasticidade. Um diagn´ostico visual pode ser feito olhando ao gr´aﬁco dos res´ıduos ei = yi − ˆyi = yi − ˆα − ˆβ xi contra os valores ajustados ˆyi. Usualmente, procuramos veriﬁcar visualmente se existe algum padr˜ao que poderia implicar que a variˆancia poderia estar variando com o valor esperado da resposta yi. Por exemplo, ´e comum que quanto maior ´e o valor esperado de yi (= α + β xi), maior ´e a variˆancia de yi. Nesse caso, o gr´aﬁco deveria mostrar uma dispers˜ao maior dos eis a medida que os ˆyis aumentam. 9 0 200 400 600 800−400−2000200400600 Fitted valuesResiduals Residuals vs Fitted 16 12 21 −2 −1 0 1 2−1012 Theoretical QuantilesStandardized residuals Normal Q−Q 16 12 21 Figura 2: Gr´aﬁcos para diagn´ostico do modelo no Exemplo 1: (a) Res´ıduos versus valores ajustados e (b) gr´aﬁco q-q para os res´ıduos do modelo. O suposto de normalidade pode ser checado visualmente de v´arias formas. A mais comum ´e usando o assim chamado gr´aﬁco Q-Q dos res´ıduos. Se os erros fossem normal- mente distribu´ıdos, esse gr´aﬁco deveria mostrar uma forte tendˆencia linear. Exemplo 1. (Continua¸c˜ao). A Figura 2 mostra esses dois gr´aﬁcos constru´ıdos com a linguagem R. O primeiro gr´aﬁco (res´ıduos vs. valores ajustados) n˜ao parece mostrar nenhum padr˜ao de variabilidade que ﬁzesse duvidar o suposto de homocedasticidade. O segundo gr´aﬁco (q-q dos res´ıduos) mostra tendˆencia linear, embora existem algumas observa¸c˜oes com valores pequenos de ˆyi que poderiam fugir dessa tendˆencia. Em geral, o diagn´ostico visual sugere que os dois supostos podem ser razo´aveis para esses dados. 10","libVersion":"0.5.0","langs":""}