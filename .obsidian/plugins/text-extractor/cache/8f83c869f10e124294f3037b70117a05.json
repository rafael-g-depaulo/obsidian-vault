{"path":".obsidian/plugins/text-extractor/cache/8f83c869f10e124294f3037b70117a05.json","text":"Universidade de Bras´ılia Instituto de Ciˆencias Exatas Departamento de Estat´ıstica Probabilidade e Estat´ıstica 2 1o semestre de 2020 Gustavo L. Gilardoni Testes Chi-quadrado ou Testes de Aderˆencia e de Associa¸c˜ao ou Introdu¸c˜ao `a Inferˆencia para Dados de Contagem 26 de Novembro de 2020 0 Introdu¸c˜ao Exemplo 1. Um dado foi lan¸cado n = 100 vezes obtendo-se o resultado na Tabela 1. ´E razo´avel assumir que o dado ´e n˜ao-viesado, no sentido que as suas seis faces tˆem a mesma probabilidade? Face 1 2 3 4 5 6 Total Frequˆencia (ni) 21 13 22 20 13 11 100 Freq. esperada 16.67 16.67 16.67 16.67 16.67 16.67 100 Tabela 1: Resultado de n = 100 lan¸camentos de um dado (Exemplo 1). Exemplo 2. Uma companhia mineradora usa um n´umero grande de correias transpor- tadoras. Falhas nestes equipamentos impactam tanto o aspecto econˆomico quanto o da seguran¸ca da opera¸c˜ao. A Tabela 2 descreve o n´umero de falhas para n = 50 motores de correias transportadoras no per´ıodo de um ano. Com base nesses dados, ser´ıa razo´avel assumir que a distribui¸c˜ao do n´umero de falhas segue uma distribui¸c˜ao de Poisson? # de Falhas 0 1 2 3 Total # de Motores 24 10 12 4 50 probs. est. (ˆpi) 0.399 0.367 0.169 0.066 1 Freq. esperada 19.926 18.332 8.433 3.309 50 Tabela 2: N´umero de falhas em um ano para 50 motores de correias transportadoras usadas por uma companhia mineradora. (Exemplo 2). Exemplo 3. A Tabela 3 mostra as notas obtidas num curso de C´alculo por duas amos- tras: (i) a primeira com n1 = 100 alunos e (ii) a segunda com n2 = 50 alunas. Existe evidˆencia no sentido que, na popula¸c˜ao de referˆencia, a distribui¸c˜ao das notas ´e diferente para os alunos do que para as alunas? 1 Nota II MI MM MS SS Total Homens 13 15 37 22 13 100 Mulheres 3 4 15 15 13 50 Total 16 19 52 37 26 150 Tabela 3: Distribui¸c˜ao das notas para uma amostra de n1 = 100 alunos e outra de n2 = 50 alunas numa disciplina de C´alculo (Exemplo 3). Exemplo 4. A Tabela 4 mostra a distribui¸c˜ao das notas para uma amostra de n = 200 alunos de uma turma de Estat´ıstica B´asica, classiﬁcada de acordo ao sexo do aluno. Existe evidˆencia no sentido que a nota depende do sexo do aluno (ou vice-versa)? Nota II MI MM MS SS Total Homens 10 14 36 31 21 112 Mulheres 11 16 25 23 13 88 Total 21 30 61 54 34 200 Tabela 4: Distribui¸c˜ao das notas para uma amostra de n = 200 alunos classiﬁcados por sexo numa disciplina de Estat´ıstica B´asica (Exemplo 4). Cada um desses exemplos corresponde `a uma t´ecnica que ser´a estudada nesta uni- dade: • Exemplo 1: Teste de Aderˆencia (Goodness-of-Fit no inglˆes) com probabilidades especiﬁcadas sob H0; • Exemplo 2: Teste de Aderˆencia com probabilidades desconhecidas sob H0; • Exemplo 3: Teste de homogeneidade; • Exemplo 4: Teste de independˆencia. 1 A distribui¸c˜ao multinomial A distribui¸c˜ao Binomial aparece relacionada com amostragem em popula¸c˜oes classiﬁca- das em duas classes, usualmente denominadas de “sucesso” e “fracasso”. Formalmente, consideramos n experimentos dicotˆomicos, tamb´em chamados de Ensaios de Bernoulli • Os n ensaios s˜ao independentes, no sentido que o resultado (sucesso ou fracasso) de um deles n˜ao ter´a nenhum efeito na probabilidade de observarmos sucesso ou fracasso em qualquer um dos outros. • Os n ensaios s˜ao idˆenticos, no sentido que todos eles tem a mesma probabilidade de sucesso p e de fracasso q = (1 − p). 2 • No caso de popula¸c˜oes ﬁnitas, essas duas propriedades aparecem quando fazemos amostragem com reposi¸c˜ao. • Denotando por X a vari´avel aleat´oria que representa o n´umero de sucessos nos n ensaios, segue que P(X = x) = ( n x ) px (1 − p) n−x = n! x! (n − x)! px (1 − p) n−x (1) para x = 0, 1, . . . , n. A Distribui¸c˜ao Multinomial ´e uma generaliza¸c˜ao da Binomial quando os ensaios (ou a popula¸c˜ao sob estudo) s˜ao Politˆomicos ao inv´es de dicotˆomicos. Um ensaio politˆomico pode ter um n´umero ﬁnito k ≥ 2 de resultados. Quando k = 2 temos o caso dicotˆomico e a distribui¸c˜ao do n´umero de sucessos ´e Binomial. Quando k > 2, a distribui¸c˜ao do vetor formado pelo n´umero de indiv´ıduos em cada classe ´e chamada de Multinomial. Formalmente: • Temos n ensaios politˆomicos, onde o resultado de cada ensaio pode assumir k valores que denotamos por C1, C2, . . . , Ck (ou simplesmente por 1, . . . , k); • Os n ensaios s˜ao independentes, no sentido que o resultado de um (ou um grupo) deles n˜ao afeta as probabilidades relativas aos outros ensaios; • Os n ensaios s˜ao idˆenticos, no sentido que as probabilidades das classes C1, C2, . . . , Ck, que denotamos por p1, p2, . . . , pk s˜ao as mesmas em todos os ensaios • ´E claro que pi ≥ 0 (i = 1, 2, . . . , k) e k∑ i=1 pi = 1 (2) • Denote por X = (X1, X2, . . . , Xk) o evento que nos n ensaios foram observados X1 vezes a classe C1, X2 vezes a classe C2 e assim por diante. • ´E claro da descri¸c˜ao do problema que X pode assumir valores (x1, x2, . . . , xk) tais que os xis s˜ao inteiros e xi ≥ 0 (i = 1, 2, . . . , k) e k∑ i=1 xi = n (3) (compare com a equa¸c˜ao (2)!) Portanto, embora tanto o vetor dos pis quanto o das quantidades aleat´orias Xis tem k componentes, a sua dimens˜ao efetiva ´e (k − 1). • A distribui¸c˜ao do vetor (X1, . . . , Xk) ´e chamada Multinomial com parˆametros n e p = (p1, . . . , pk) e ´e dada por P(X1 = x1, X2 = x2, . . . , Xk = xk) = ( n x1, . . . , xk ) k∏ i=1 pxi i = n! x1! x2! . . . xk! p x1 1 px2 2 . . . p xk k , (4) onde os xis satisfazem a equa¸c˜ao (3). 3 • Se X = (X1, . . . , Xk) ∼ Multinomial(n,p = (p1, . . . , pk)), ent˜ao cada um dos Xi segue uma distribui¸c˜ao Binomial(n,pi). Portanto E(Xi) = n pi e Var(Xi) = n pi (1 − pi) . Ainda, para i ̸= j, cov(Xi, Xj) = E[(Xi − n pi) (Xj − n pj)] = −n pi pj . Exemplo 1 (Continua¸c˜ao). Se o dado do exemplo for efetivamente n˜ao-viesado, no sentido que as seis faces tem a mesma probabilidade, ent˜ao a distribui¸c˜ao dos n´umeros de cada face nos 100 lan¸camentos ´e Multinomial com n = 100 e p = (1/6, 1/6, . . . , 1/6). Ao realizar os n = 100 lan¸camentos o valor esperado do n´umero de vezes que aparece a face “1” ´e E(X1) = n p1 = (100)(1/6) . = 16.67. 2 Testes de Aderˆencia Seja X = (X1, . . . , Xk) ∼ Multinomial(n,p = (p1, . . . , pk)). Queremos testar a H0 que p = p0 = (p0,1, p0,2, . . . , p0,k) contra a Ha que p ̸= (p0,1, p0,2, . . . , p0,k) (i.´e. pelo menos um dos pi ´e diferente do que o correspondente p0,i). Est´a ´e a situa¸c˜ao do Exemplo 1 onde k = 6, n = 100 e p0 = (1/6, 1/6, 1/6, 1/6, 1/6, 1/6). No seguinte exemplo temos uma situa¸c˜ao onde as probabilidades pi,0 n˜ao s˜ao todas iguais. Exemplo 5. A colora¸c˜ao das ﬂores de certas plantas (snapdragon, ou boca-de-lobo) mostra um fenˆomeno de dominˆancia parcial. Sucintamente, temos dois gens A e a de forma que a combina¸c˜ao AA produz ﬂores roxas, as combina¸c˜oes Aa e aA produzem ﬂores rosas e a combina¸c˜ao aa produz ﬂores brancas. De acordo a esta teoria, numa popula¸c˜ao em equilibrio dever´ıamos ter 25% de ﬂores roxas e brancas e 50% de ﬂores rosas. A Tabela 5 mostra a distribui¸c˜ao das cores para uma amostra de n = 1000 mudas. Queremos saber se essa distribui¸c˜ao ´e consistente com a hip´otese da popula¸c˜ao estar em equil´ıbrio. Portanto, a nossa hip´otese nula ´e que p1,0 = p3,0 = 0.25 e p2,0 = 0.50. Cor Roxa Rosa Branca Total Freq. obs. 262 535 203 1000 Freq. esp. 250 500 250 1000 Tabela 5: Cores das ﬂores para uma amostra de n = 1000 mudas de snapdragon (Exemplo 5). Uma primeira aproxima¸c˜ao para testar H0 ´e comparar o n´umero de vezes que ocorre cada classe (xi) com o seu valor esperado sob H0, E(Xi | H0) = n pi,0 ( a terceira linha nas Tabelas 1 e 5. Por exemplo, poder´ıamos considerar a soma do quadrado da diferen¸ca entre a frequˆencia observada e a esperada. No exemplo 1 ter´ıamos (21 − 16.67)2 + (13 − 16.67)2 + · · · + (11 − 16.67)2 . = 117.33, que na literatura ´e usualmente denotado por 4 ∑ (nobs − nesp)2 (leia “n” como “frequˆencia”). Ainda, ´e claro que sob a Ha esperar´ıamos que est´a soma fosse maior do que sob a H0. No entanto, proceder dessa forma tem um problema que ´e mais f´acil de visualizar no Exemplo 5. Suponha nesse caso que tiv´essemos observado na amostra de n = 1000 mudas x1 = 260 ﬂores roxas e x2 = 510 ﬂores rosas. A contribui¸c˜ao desses dos valores para a soma acima seria a mesma, (260 − 250)2 = (510 − 500)2 = 100, embora parece claro intuitivamente que uma diferen¸ca de 10 ﬂores roxas ´e mais importante do que uma diferen¸ca de 10 ﬂores rosas, pois, por exemplo, 260 ´e 4% a mais do que 250, enquanto 510 ´e somente 2% a mais do que 500. Por esse motivo, ´e usual na soma referida acima dividir cada quadrado pela frequˆencia esperada. • Problema: Dada a observa¸c˜ao x1, . . . , xk de uma distribui¸c˜ao Multinomial (n,p = (p1, . . . , pk)). Queremos testar a H0 que p = p0 = (p0,1, p0,2, . . . , p0,k) contra a Ha que p ̸= (p0,1, p0,2, . . . , p0,k) • Estat´ıstico do teste: χ2 obs = k∑ i=1 (xi − n pi,0)2 n pi,0 (5) ou χ2 obs = ∑ (nobs − nesp)2 nesp . (6) • Sob H0, mostra-se que quando n tende a ∞, a distribui¸c˜ao do estat´ıstico tende a uma χ2 k−1. A explica¸c˜ao intuitiva para termos (k − 1) graus de liberdade ´e que temos somente (k − 1) probabilidades independentes, pois ∑k i=1 pi = 1. • Sob a hip´otese alternativa, esperamos que χ2 obs seja grande. Portanto, ao n´ıvel de signiﬁcˆancia aproximado 100α%, a H0 ´e rejeitada se χ2 obs > χ2 (k−1);α. O p-valor do teste ´e P(χ2 (k−1) > χ2 obs). • Embora o resultado anterior faz referˆencia a n → ∞, ´e claro que n ser´a ﬁnito em qualquer aplica¸c˜ao e pode ocorrer que a convergˆencia `a distribui¸c˜ao limite seja muito devagar. Usualmente recomenda-se que esse teste seja aplicado somente se n pi,0 > 5 para todo i. Quando isso n˜ao ocorre, precisa (i) aumentar o tamanho amostral n ou (ii) colapsar classes com frequˆencias esperadas pequenas at´e que todas as frequˆencias esperadas sejam maiores do que 5, embora ´e preciso mencionar que nesse caso vamos estar testando uma hip´oteses (ligeiramente?) diferente. Exemplo 1 (Continua¸c˜ao). O estat´ıstico observado ´e χ2 obs = (21 − 16.67)2/16.67 + (13 − 16.67)2/16.67 + · · · + (11 − 16.67)2/16.67 . = 7.04. Usando α = 0.05, o valor cr´ıtico ´e χ2 5,0.05 . = 11.07 e portanto n˜ao rejeitamos a H0 que o dado ´e n˜ao-viesado. O p-valor do teste ´e P(χ2 5 > 7.04) . = 0.22. Exemplo 5 (Continua¸c˜ao). O estat´ıstico observado ´e χ2 obs = (262 − 259)2/250 + (535 − 500)2/500 + (203 − 250)2/250 . = 11.86. Usando α = 0.05, o valor cr´ıtico ´e χ2 2,0.05 . = 5.99 e portanto rejeitamos a H0 que a popula¸c˜ao est´a em equilibrio. O p-valor do teste ´e P(χ2 2 > 11.86) . = 0.003 ou 0.3%. 5 Quando as probabilidades das classes dependem de um ou mais parˆametros desco- nhecidos (θ1, θ2 . . . , θr), como no Exemplo 2, ´e necess´ario estimar primeiro os parˆametros para depois calcular as probabilidades das classes. Nesse caso o c´alculo do estat´ıstico χ2 ´e semelhante ao discutido acima, com a diferen¸ca que para calcular as frequˆencias espe- radas precisamos primeiro calcular primeiro estimativas (ˆθ1, ˆθ2 . . . , ˆθr), depois as proba- bilidades estimadas das classes ˆpi = pi(ˆθ1, . . . , ˆθk) e ﬁnalmente as frequˆencias esperadas ni ˆpi. Quando os parˆametros s˜ao estimados pelo m´etodo de M´axima Verossimilhan¸ca (ou algum outro m´etodo que ´e equivalente a ele quando n → ∞), mostra-se que a distri- bui¸c˜ao limite do estat´ıstico χ2 ´e χ2 com (k − 1 − r) graus de liberdade. Isto ´e, por cada parˆametro que ´e necess´ario estimar para calcular as frequˆencias esperadas, perde-se um grau de liberdade na distribui¸c˜ao limite. Observe que devemos ter cuidado para que as probabilidades estimadas das classes somem um ou, em outras palavras, as classes devem ser deﬁnidas de forma que sejam exaustivas (veja o exemplo abaixo). Exemplo 2 (Continua¸c˜ao). Como o problema n˜ao espec´ıﬁca o valor de θ da distribui¸c˜ao de Poisson, precisamos estima-lo. A estimativa de m´axima verossimilhan¸ca ´e a m´edia das observa¸c˜oes ˆθ = ¯x = [(0) (24) + (1) (10) + (2) (12) + (3) (4)]/50 . = 0.92 Calculamos depois as probabilidades das classes ˆp0 = P(X = 0 | ˆθ) = e−ˆθ ˆθ0 0! . = e −0.92 . = 0.398 , ˆp1 = P(X = 1 | ˆθ) = e−ˆθ ˆθ1 1! . = (0.92) e−0.92 . = 0.367 , ˆp2 = P(X = 2 | ˆθ) = e−ˆθ ˆθ2 2! . = (0.92)2 e−0.92 2 . = 0.169 e ﬁnalmente ˆp3 = P(X ≥ 3 | ˆθ) = 1 − ˆp0 − ˆp1 − ˆp2 . = 0.066 . Veja que a ´ultima classe foi deﬁnida como “X ≥ 3” (ao inv´es de “X = 3”), de forma que as probabilidades estimadas somem um. Com as probabilidades estimadas calculamos as frequˆencias esperadas n ˆpi (veja a Tabela 2) e o estat´ıstico χ2 obs = (24 − 19.926)2/19.926 + · · · + (4 − 3.309)2/3.309 . = 6.273 Esse estat´ıstico ´e comparado com a cauda `a direita da distribui¸c˜ao χ2 com (k − 1 − r) = (4 − 1 − 1) = 2 graus de liberdade. Por exemplo, ao n´ıvel de signiﬁcˆancia α = 0.10, o valor da tabela ´e χ2 2;0.90 . = 4.605, de forma que rejeitamos a H0 da distribui¸c˜ao ser Poisson. O p-valor do teste ´e P(χ2 2 > 6.273) . = 0.043 ou 4.3%. Observa¸c˜ao 1. Como explicamos acima, a convergˆencia da distribui¸c˜ao do estat´ıstico χ2 pode ter problemas quando alguma das frequˆencias esperadas ´e menor do que 5, que ´e o caso do exemplo para a classe “X ≥ 3”. Portanto, poderia ser indicado nesse caso agrupar as duas ´ultimas classes numa outra que chamar´ıamos “X ≥ 2”. Nesse caso ter´ıamos somente um grau de liberdade na distribui¸c˜ao limite. Quando a distribui¸c˜ao da vari´avel observada ´e continua, ´e necess´ario agrupar os dados por intervalos para deﬁnir as respectivas classes. 6 xdensidade 60 70 80 90 100 1100.000.010.020.030.040.05 Figura 1: Histograma para os dados da Tabela 6. Exemplo 6. A Tabela 6 mostra o tempo (em minutos) que cada aluno de uma turma de uma disciplina introdut´oria de estat´ıstica levou para terminar uma prova (os dados est˜ao ordenados para facilitar os c´alculos). A Figura 1 mostra um histograma desses dados produzido com a linguagem R. O objetivo do estudo ´e avaliar se ´e razo´avel supor que o tempo para completar a prova segue uma distribui¸c˜ao Normal. 58 61 63 64 64 65 65 65 65 67 67 68 69 72 72 73 73 73 73 75 76 76 76 77 77 78 78 78 79 79 79 80 80 80 81 81 82 83 84 84 85 87 88 88 92 93 93 95 102 107 Tabela 6: Tempo (em minutos) de 50 alunos para completar uma prova de um curso de estat´ıstica b´asica. Para deﬁnir os intervalos e agrupar os dados, usamos inicialmente a op¸c˜ao padr˜ao da fun¸c˜ao hist do R. O resultado est´a mostrado na Tabela 7. Para o c´alculo das frequˆencias esperadas calculamos primeiro estimadores para a m´edia e a variˆancia da distribui¸c˜ao Normal; ˆµ = ¯x . = 77.4 e ˆσ2 = s2 = (n − 1)−1 ∑n i=1(xi − ¯x)2 . = (10.51)2. As frequˆencias esperadas s˜ao ent˜ao as probabilidades de cada intervalo numa distribui¸c˜ao Normal com essa m´edia e variˆancia. Por exemplo, para o segundo intervalo calculamos primeiro P(60 < X ≤ 65) . = 0.0701 e ent˜ao nesp . = n (0.0701) . = (50) (0.0701) . = 3.51. Como pode ser visto da tabela, existem v´arios intervalos (6 no total) nos extremos cujas frequˆencias esperadas s˜ao menores que 5. Dessa forma, para o c´alculo do estat´ıstico χ2 agrupamos primeiro os dois primeiros intervalos e os ´ultimos quatro, de forma que to- das as classes tivessem frequˆencias esperadas acima de 5. O resultado desse agrupamento est´a mostrado na Tabela 8. 7 Int. (−∞,60] (60,65] (65,70] (70,75] (75,80] (80,85] nobs 1 8 4 7 14 7 nesp 2.44 3.51 6.08 8.45 9.40 8.38 Int. (85,90] (90,95] (95,100] (100,105] (105,∞) nobs 3 4 0 1 1 nesp 5.98 3.41 1.56 0.57 0.22 Tabela 7: Frequˆencias observadas e esperadas para os intervalos obtidos com a op¸c˜ao padr˜ao da fun¸c˜ao hist e as estimativas ˆµ . = 77.4 e ˆσ2 . = (10.51)2. Finalmente, calculamos o estat´ıstico do teste de acordo `a equa¸c˜ao (6), obtendo χ2 obs . = (9 − 5.95)2/5.95 + · · · + (6 − 5.76)2/5.76 . = 6.493. Como temos 7 intervalos e estimamos dois parˆametros (µ e σ2), devemos usar a distribui¸c˜ao chi2 com 7 − 1 − 2 = 4 graus de liberdade. Ao n´ıvel de signiﬁcˆancia 5%, o valor cr´ıtico ´e χ2 4;0.05 . = 9.488, de forma que n˜ao rejeitamos a hip´otese nula de normalidade. O p-valor do teste ´e P(χ2 4 > 6.493) . = 0.165. Int. (−∞,65] (65,70] (70,75] (75,80] (80,85] (85,90] (90, ∞] nobs 9 4 7 14 7 3 6 nesp 5.95 6.08 8.45 9.40 8.38 5.98 5.76 Tabela 8: Frequˆencias observadas e esperadas para os intervalos ﬁnais e as estimativas ˆµ . = 77.4 e ˆσ2 . = (10.51)2. Note que todas as frequˆencias esperadas s˜ao maiores do que 5. Observa¸c˜ao 2. Como pode ser visto do exemplo, a deﬁni¸c˜ao dos intervalos que deﬁnem as classes ´e arbitr´aria e seria poss´ıvel que a nossa decis˜ao mude dependendo de como s˜ao deﬁnidas as classes. Dessa forma, a metodologia deve ser considerada somente como uma forma de explorar os dados e n˜ao um procedimento formal para testar normalidade. Observa¸c˜ao 3. Na verdade, estamos somente testando se as probabilidades dos inter- valos por n´os deﬁnidos coincidem com as de uma distribui¸c˜ao Normal. Existem testes mais espec´ıﬁcos e apropriados para normalidade, tais como o crit´erio de Kolmogorov e von Mises ou o teste de Shapiro e Wilk, mas o tratamento deles ﬁca fora do escopo da nossa disciplina. 3 Teste de homogeneidade Suponha que temos I popula¸c˜oes politˆomicas tais que os seus indiv´ıduos podem ser classiﬁcados nas categorias A1, A2, . . . , AJ . Seja pij a probabilidade da categoria Aj na i´esima popula¸c˜ao, como indicado Tabela 9. Chama-se teste de homogeneidade o teste da hip´otese nula que as I distribui¸c˜oes s˜ao iguais. Mais precisamente, a H0 espec´ıﬁca que p1j = p2j = · = pIj para todo j = 1, . . . , J (i.´e., que os elementos das J colunas da Tabela 9, s˜ao todos iguais). 8 Classe Popula¸c˜ao A1 A2 · · · Aj · · · AJ Total 1 p11 p12 · · · p1j · · · p1J 1 2 p21 p22 · · · p2j · · · p2J 1 ... ... ... ... ... ... ... ... i pi1 pi2 · · · pij · · · piJ 1 ... ... ... ... ... ... ... ... I pI1 pI2 · · · pIj · · · pIJ 1 Tabela 9: I popula¸c˜oes classiﬁcadas em J classes ou eventos. Frequentemente, para realizar o teste, observa-se uma amostra de cada popula¸c˜ao considerada e contam-se quantos indiv´ıduos pertencem a cada uma das classes. De- notamos nij o n´umero de indiv´ıduos da i-´esima amostra que est˜ao na classe Aj e por ni• = ∑J j=1 nij o tamanho da i-´esima amostra. De forma semelhante podemos deﬁnir o total de indiv´ıduos na classe Aj, n•j = ∑I i=1 nij, e o total de indiv´ıduos observados n = n•• (Veja a Tabela 10). Classe Popula¸c˜ao A1 A2 · · · Aj · · · AJ Totais 1 n11 n12 · · · n1j · · · n1J n1• 2 n21 n22 · · · n2j · · · n2J n2• ... ... ... ... ... ... ... ... i ni1 ni2 · · · nij · · · niJ ni• ... ... ... ... ... ... ... ... I nI1 nI2 · · · nIj · · · nIJ nI• Totais n•1 n•2 · · · n•j · · · n•J n = n•• Tabela 10: . Para construir o estat´ıstico do teste ´e ´util pensar como estimar´ıamos as probabilidades da Tabela 9 no caso da H0 ser ou n˜ao ser verdadeira: • Come¸camos pelo caso que H0 ´e falsa, isto ´e, que n˜ao temos nenhuma informa¸c˜ao sobre a rela¸c˜ao entre as probabilidades da Tabela. Nesse caso, a melhor forma de estimar pij, a probabilidade da classe Aj na i-´esima popula¸c˜ao, ´e com a propor¸c˜ao de indiv´ıduos dessa classe na respectiva amostra, ˆpij = nij/ni•. • Veja que, nesse caso, temos I J probabilidades mas vamos precisar estimar “so- mente” I (J − 1) delas, pois a soma de cada linha da Tabela 9 ´e igual a um. • Quando H0 ´e verdadeira, as I popula¸c˜oes tem a mesma distribui¸c˜ao de probabili- dade. Em outras palavras, as I linhas da Tabela 9 s˜ao idˆenticas. Se as popula¸c˜oes 9 tem a mesma distribui¸c˜ao de probabilidade, podemos agrup´a-las e considerar o con- junto de todos n = n•• como se fosse uma ´unica amostra dessa grande popula¸c˜ao. Logo, as estimativas das probabilidades das classe s˜ao ˜pij = n•j/n••. • Veja que, quando H0 ´e verdadeira, temos inicialmente J probabilidades mas pre- cisamos estimar “somente” (J − 1), pois a soma de todas elas tem que ser um. A constru¸c˜ao da estat´ıstica do teste de homogeneidade passa ent˜ao pela constru¸c˜ao de uma medida da “distˆancia” (ou, na terminologia da Teor´ıa da Informa¸c˜ao, da “di- vergˆencia”) entre as distribui¸c˜oes de probabilidade deﬁnidas pelas estimativas ˆpij e ˜pij. Se a “distˆancia” for “grande”, isso signiﬁca que as estimativas das probabilidades da Ta- bela 9 s˜ao muito diferentes segundo assumirmos que H0 ´e verdadeira ou n˜ao, e portanto vamos rejeitar a H0 de homogeneidade. Existem muitas medidas de distˆancia ou divergˆencia que podem ser usadas. A mais tradicional, devida ao estat´ıstico Karl Pearson no ﬁnal do s´eculo XIX, ´e chamada χ2 de Pearson e ´e deﬁnida por χ 2(ˆp; ˜p) = ∑ i,j ni• (ˆpij − ˜pij)2 ˜pij [cuidado: essa medida n˜ao ´e sim´etrica, assim que em geral χ2(ˆp; ˜p) ̸= χ2(˜p; ˆp)]. Uma vez que decidimos usar a divergˆencia χ2, precisamos deﬁnir o signiﬁcado de “grande” ou, em outras palavras, achar uma distribui¸c˜ao de referˆencia para fazer o teste. Nesse sentido, o resultado fundamental ´e que quando todos os tamanhos amostrais tendem a inﬁnito, a distribui¸c˜ao de χ2(ˆp; ˜p) se aproxima de uma distribui¸c˜ao χ2 com (I − 1) (J − 1) graus de liberdade. Duas observa¸c˜oes s˜ao importantes aqui: • Como em todos os problemas que temos visto anteriormente, os graus de liberdade do estat´ıstico χ2 ´e a diferen¸ca entre o n´umero de parˆametros livres no caso geral [I (J − 1)] e o n´umero de de parˆametros livres sob H0 (J − 1). • Deﬁna nobs ij = nij e nesp ij = ni• ˜pij = ni• n•j/n. Ent˜ao χ 2 obs = χ2(ˆp; ˜p) = ∑ i,j ni• (ˆpij − ˜pij)2 ˜pij = ∑ i,j ni• (nij/ni• − n•j/n)2 n•j/n = ∑ i,j (nobs ij − nesp ij )2 nesp ij (7) [compare com a equa¸c˜ao (6)] Exemplo 3 (Continua¸c˜ao). As tabelas 11-13 mostram respectivamente (i) as probabi- lidades estimadas no caso geral, (ii) as probabilidades estimadas sob a restri¸c˜ao de ho- mogeneidade e (iii) as frequˆencias esperadas sob a restri¸c˜ao de homogeneidade. Usando por exemplo as frequˆencias observadas da Tabela 3 e as esperadas da Tabela 13, calcu- lamos χ2 obs . = (13 − 10.667)2/10.667 + · · · + (13 − 8.667)2/8.667 . = 7.407. Como temos I (J −1)−(J −1) = (I −1) (J −1) = 4 graus de liberdade, ao n´ıvel de signiﬁcˆancia de 5%, o valor da tabela ´e χ2 4,0.05 . = 9.488, de forma que n˜ao rejeitamos a H0 de homogeneidade. Em outras palavras, ao n´ıvel de signiﬁcˆancia de 5%, n˜ao existe evidˆencia que a distri- bui¸c˜ao das notas ´e diferentes segundo o sexo. O p-valor do teste ´e P(χ2 4 > 7.407) . = 0.116. 10 Nota II MI MM MS SS Total Homens 0.13 0.15 0.37 0.22 0.13 1 Mulheres 0.06 0.08 0.30 0.30 0.26 1 Tabela 11: Probabilidades estimadas sem restri¸c˜oes para o Exemplo 3: ˆpij = nij/ni•. Nota II MI MM MS SS Total Homens 0.107 0.127 0.347 0.247 0.173 1 Mulheres 0.107 0.127 0.347 0.247 0.173 1 Tabela 12: Probabilidades estimadas sob restri¸c˜ao de homogeneidade para o Exemplo 3: ˜pij = n•j/n••. 4 Testes de independˆencia Suponha uma ´unica popula¸c˜ao classiﬁcada de acordo a dois fatores ou caracter´ısticas, digamos A1, A2, . . . , AI e B1, B2, . . . , BJ . Seja pij a probabilidade de um indiv´ıduo esco- lhido ao acaso dessa popula¸c˜ao possuir as caracter´ısticas Ai e Bj simultaneamente, pi• = ∑J j=1 pij a probabilidade (marginal) dele possuir a caracater´ıstica Ai e p•j = ∑I i=1 pij a probabilidade (marginal) dele possuir a caracater´ıstica Bj (veja a Tabela 14). Por outro lado, suponha que foi observada uma ´unica amostra de tamanho n dessa popula¸c˜ao e os indiv´ıduos foram classiﬁcados de acordo aos dois fatores A e B, de forma que a frequˆencia observada da classe Ai ∩ Bj foi nij. Deﬁna ainda a frequˆencia associada com a classe Ai, ni• = ∑ j nij e com a classe Bj, n•j = ∑ i nij. A situa¸c˜ao aparece descrita na Tabela 15 Queremos testar a H0 que os dois fatores s˜ao (probabilisticamente) independentes. Lembrando que dois eventos s˜ao independentes se a probabilidade da sua interse¸c˜ao ´e igual ao produto das probabilidades dos eventos, no caso de independˆencia deveriamos ter que pij = P(Ai ∩ Bj) = P(Ai) P(Bj) = pi• p•j. Portanto as nossas hip´oteses s˜ao H0 : pij = pi• p•j para todo par (i, j) e Ha : pij ̸= pi• p•j para pelo menos um par (i, j) . O procedimento do teste ´e muito parecido com o rec´em discutido teste de homogenei- dade. Isto ´e, come¸camos por ver como estimar´ıamos as probabilidades pij dependendo da H0 ser verdadeira ou n˜ao: • Quando H0 ´e falsa, n˜ao temos nenhuma informa¸c˜ao sobre a rela¸c˜ao entre as proba- bilidades da Tabela 14. Nesse caso, a melhor forma de estimar pij, a probabilidade da interse¸c˜ao de Ai e Bj, ´e com a propor¸c˜ao de indiv´ıduos que possuem essa ca- racter´ıstica na respectiva amostra. Em outras palavras, ˆpij = nij/ni•. • Veja que, nesse caso, temos (IJ) probabilidades mas vamos precisar estimar “so- mente” (IJ − 1) delas, pois a soma de todas as probabilidades da Tabela 14 ´e igual 11 Nota II MI MM MS SS Total Homens 10.667 12.667 34.667 24.667 17.333 100 Mulheres 5.333 6.333 17.333 12.333 8.667 50 Tabela 13: Frequˆencias esperadas no caso de homogeneidade no Exemplo 3: nesp ij = ni• ˜pij = ni• n•j/n•• B1 B2 · · · Bj · · · BJ Total A1 p11 p12 · · · p1j · · · p1J p1• A2 p21 p22 · · · p2j · · · p2J p2• ... ... ... ... ... ... ... ... Ai pi1 pi2 · · · pij · · · piJ pi• ... ... ... ... ... ... ... ... AI pI1 pI2 · · · pIj · · · pIJ pI• Total p•1 p•2 · · · p•j · · · p•J 1 Tabela 14: Uma ´unica popula¸c˜ao classiﬁcada de acordo a dois fatores, A com I n´ıveis e B com J n´ıveis. a um. • Quando H0 ´e verdadeira ser´ıa suﬁciente estimar somente as probabilidades mar- ginais pi• e p•j, pois depois as outras probabilidades da Tabela 14 seriam obtidas como o produto das duas marginais correspondentes. Portanto, podemos deﬁnir as estimativas ˜pi• = ni•/n e ˜p•j = n•j/n e depois ter´ıamos simplesmente que ˜pij = ˜pi• ˜p•j. • Veja que, quando H0 ´e verdadeira, temos (I + J) probabilidades marginais mas, dessas, somente precisamos estimar (I + J − 2), pois ∑ i pi• = ∑ j p•j = 1. B1 B2 · · · Bj · · · BJ Total A1 n11 n12 · · · n1j · · · n1J n1• A2 n21 n22 · · · n2j · · · n2J n2• ... ... ... ... ... ... ... ... Ai ni1 ni2 · · · nij · · · niJ ni• ... ... ... ... ... ... ... ... AI nI1 nI2 · · · nIj · · · nIJ nI• Total n•1 n•2 · · · n•j · · · n•J n = n•• Tabela 15: Uma ´unica amostra classiﬁcada de acordo a dois fatores, A com I n´ıveis e B com J n´ıveis. 12 O estat´ıstico do teste ´e χ2 obs = ∑ i,j n (ˆpij − ˜pij)2 ˜pij = ∑ i,j (nobs ij − nesp ij )2 nesp ij , onde nobs ij = n ˆpij = nij e nobs ij = n ˜pij = ni• n•j/n [novamente, compare com as equa¸c˜oes (6) e (7)]. Esse valor ´e comparado com valores cr´ıticos da distribui¸c˜ao χ2 com (IJ − 1) − (I + J − 2) = (I − 1)(J − 1) graus de liberdade, de forma que a H0 de independˆencia ´e rejeitada se χ2 obs > χ2 (I−1)(J−1);α. Exemplo 4 (Continua¸c˜ao). A Tabela 4 mostra as frequˆencias observadas nij. Comm base nela calculamos as probabilidades estimadas sem restri¸c˜ao (ˆpij = nij/n) e sob a restri¸c˜ao de independencia (˜pij = ni•n•j/n2) e as frequˆencias esperadas sob H0 (nesp ij = ni•n•j/n), mostradas respectivamente nas tabelas 16-18. Nota II MI MM MS SS Total Homens 0.050 0.070 0.180 0.155 0.105 0.56 Mulheres 0.055 0.080 0.125 0.115 0.065 0.44 Total 0.105 0.150 0.305 0.270 0.170 1 Tabela 16: Probabilidades estimadas sem restri¸c˜ao no Exemplo 4 (ˆpij = nij/n). Nota II MI MM MS SS Total Homens 0.0588 0.0840 0.1708 0.1512 0.0952 0.56 Mulheres 0.0462 0.0660 0.1342 0.1188 0.0748 0.44 Total 0.105 0.150 0.305 0.270 0.170 1 Tabela 17: Probabilidades estimadas sob restri¸c˜ao de independˆencia para o Exemplo 4 (˜pij = ni•n•j/n2). Nota II MI MM MS SS Total Homens 11.76 16.80 34.16 30.24 19.04 112 Mulheres 9.24 13.20 26.84 23.76 14.96 88 Total 21 30 61 54 34 200 Tabela 18: Frequˆencias esperadas sob restri¸c˜ao de independˆencia para o Exemplo 4 (nesp ij = n ˜pij = ni•n•j/n). O estat´ıstico do teste ´e χ2 obs = (10−11.76)2/11.76+·+(13−14.96)2/14.96 . = 2.386. Ao n´ıvel de signiﬁcˆancia de 5%, o valor cr´ıtico ´e χ2 4;0.05 . = 9.488. Portanto, n˜ao rejeitamos a H0 de independˆencia. O p-valor aproximado do teste ´e P(χ2 4 > 2.386) . = 0.665 ou 66.5%. 13","libVersion":"0.2.2","langs":""}