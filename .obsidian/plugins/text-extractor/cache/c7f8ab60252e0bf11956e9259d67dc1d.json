{"path":".obsidian/plugins/text-extractor/cache/c7f8ab60252e0bf11956e9259d67dc1d.json","text":"Universidade de Bras´ılia Instituto de Ciˆencias Exatas Departamento de Estat´ıstica Probabilidade e Estat´ıstica 2 1o semestre de 2020 Gustavo L. Gilardoni An´alise de Variˆancia a um fator (one-way) 30 de Setembro de 2020 0 Introdu¸c˜ao No in´ıcio do semestre temos discutido primeiro como fazer inferˆencias para a m´edia de uma popula¸c˜ao ou tratamento e como comparar as m´edias de duas popula¸c˜oes ou dois tratamentos. Nesse ´ultimo caso o experimento foi desenhado de forma que as duas amos- tras resultassem independentes, seja porque elas eram escolhidas uma de cada popula¸c˜ao, ou porque os tratamentos eram alocados aleatoriamente `as unidades experimentais. Est´a Unidade vai tratar do problema de como comparar as m´edias de I > 2 popula¸c˜oes ou tratamentos. Parece curioso chamar de “An´alise de Variˆancia” uma ferramenta para comparar m´edias. O motivo pode ser visto a partir do seguinte exemplo. Exemplo 1. A Figura 1 (a) mostra um histograma para uma amostra x1, . . . , x100 de 100 gerada da Distribui¸c˜ao Normal Padr˜ao (o c´odigo R est´a num apˆendice ao ﬁnal das notas). O desvio padr˜ao amostral foi sx = √ (n − 1)−1 ∑100 i=1(xi − ¯x)2 . = 0.943. A Figura 1 (b) mostra o histograma de uma amostra y1, . . . , y100 obtida da seguinte forma: Dos primeiros 50 valores de xi foi subtra´ıdo o valor 1, dos ´ultimos 50 foi adicionado 1. Parece claro do segundo histograma que agora temos uma dispers˜ao consideravelmente maior. De fato, o desvio padr˜ao da amostra modiﬁcada dessa forma ´e sy . = 1.485 [o histograma 1 (b) pode ser pensado como a superposi¸c˜ao dos histogramas das primeiras 50 observa¸c˜oes, centradas em −1 e o das ´ultimas 50, centradas em +1, mostrados nas Figuras 1 (c) e (d)]. Dessa forma, comparando sy e sx podemos ter id´eia da diferen¸ca entre as m´edias das duas subamostras. Mais precisamente, denote por ¯y1 e ¯y2 respectivamente as m´edias dos primeiros e dos ´ultimos 50 valores de yi (note que, da forma que os yi foram obtidos, esperar´ıamos que ¯y1 ≈ −1 e ¯y2 ≈ +1), e por sy,1 e sy,2 os desvios padr˜oes dos primeiros e dos ´ultimos 50 yi (de forma semelhante, esperamos que tanto sy,1 quanto sy,2 sejam pr´oximos de 1, o desvio padr˜ao da distribui¸c˜ao Normal que gerou as observa¸c˜oes). Logo (99) s 2 y = 100∑ i=1(yi − ¯y) 2 = 50∑ i=1(yi − ¯y1 + ¯y1 − ¯y)2 + 100∑ i=51 (yi − ¯y2 + ¯y2 − ¯y) 2 = 50∑ i=1(yi − ¯y1) 2 + 2 (¯y1 − ¯y) 50∑ i=1(yi − ¯y1) + 50∑ i=1(¯y1 − ¯y)2 + 100∑ i=51 (yi − ¯y2)2 + 2 (¯y2 − ¯y) 100∑ i=51 (yi − ¯y2) + 100∑ i=51 (¯y2 − ¯y) 2 = (49) s2 y,1 + 2 (¯y1 − ¯y) (0) + (50) (¯y1 − ¯y) 2 + (49) s 2 y,2 + 2 (¯y2 − ¯y) (0) + (50) (¯y2 − ¯y) 2 = (49) (s 2 y,1 + s 2 y,2) + (50) [(¯y1 − ¯y)2 + (¯y2 − ¯y) 2] . (1) 1 (a) xfrequência −4 −2 0 2 405101520 (b) xfrequência −4 −2 0 2 40510152025 (c) x[1:50]frequência −4 −2 0 2 40246810 (d) x[51:100]frequência −4 −2 0 2 4024681012 Figura 1: Histogramas para o Exemplo 1 1. Fertilizante Produ¸c˜ao (kg) M´edia DP DP2 1 10.5 9.7 5.5 11.0 9.3 6.3 8.72 2.28 5.18 2 7.1 10.2 7.2 7.8 10.9 7.3 8.42 1.68 2.84 3 4.7 7.5 6.5 7.7 6.5 6.9 6.63 1.07 1.15 4 8.5 12.4 11.5 7.1 10.6 11.8 10.32 2.08 4.33 M´edia: 8.52 3.37 Tabela 1: Colheita em kg para 24 mudas de tomate usando 4 fertilizantes Nessa decomposi¸c˜ao da quantidade (99) s2 y, o termo (49) (s2 y,1 + s2 y,2) mede uma variabili- dade das observa¸c˜oes independente da sua m´edia e, de fato, esperamos que seja parecido a (100) s2 x. O termo restante, (50) [(¯y1 − ¯y)2 + (¯y2 − ¯y)2] mede uma variabilidade entre as m´edias das duas subamostras. Para a amostra do exemplo, temos que ¯x = ¯y = −0.107, ¯y1 . = −1.258, ¯y2 . = 1.043, s2 1 . = 0.990 e s2 2 = 0.878 (veja o c´alculo no apˆendice). Use esses valores para veriﬁcar e equa¸c˜ao (1). O exemplo anterior ´e artiﬁcial. O seguinte ´e real. Exemplo 2. A Tabela 1 mostra o resultado de um experimento realizado para estudar o efeito de 4 fertilizantes no cultivo de tomates. Um total de 24 mudas foram alocadas aleatoriamente 6 para cada fertilizante e ao ﬁnal do experimento o peso da colheita de cada planta foi registrado. O objetivo do estudo ´e saber se existe algum fertilizante que garante, em m´edia, uma maior colheita. A Figura 2 mostra o gr´aﬁco de pontos (dotplots) e de caixa (boxplots) para a produ¸c˜ao das plantas agrupadas pelos 4 tratamentos ou tipos de fertilizante. Tanto da tabela quanto da ﬁgura, perceve-se que as plantas que receberam o fertilizante 4 parecem ter uma produ¸c˜ao um pouco maior, enquanto as do fertilizante 3 um pouco menor. A quest˜ao 2 6 8 10 121.01.52.02.53.03.54.0 prodfert1234 6 8 10 12 Figura 2: Gr´aﬁco de pontos (dotplots) e de caixa (boxplots) para os dados da Tabela 1. fundamental ´e se essas diferen¸cas poderiam ser explicadas somente pela aleatoriedade das observa¸c˜oes, sem considerar algum tipo de efeito sistem´atico na produ¸c˜ao m´edia devido ao tipo de fertilizante. Para entender melhor essa id´eia, a Figura 3 mostra gr´aﬁcos de pontos e de caixa para 5 amostras geradas aleatoriamente da Distribui¸c˜ao Normal com m´edia µ = 8.52 e desvio padr˜ao σ = 1.83 . = √3.37. Nessas amostras n˜ao existe nenhum tipo de efeito sistem´atico dos fertilizantes e, ainda assim, para algum dos gr´aﬁcos, por exemplo o boxplot da terceira amostra), pareceria ter algum tratamento com m´edia consideravelmente maior do que a dos outros. Usualmente, para analizar dados como os da Tabela 1, testa-se primeiro se pelo menos duas das m´edias devidas aos tratamentos (fertilizantes) s˜ao diferentes. Em outras palavras, considera-se a H0 : µ1 = µ2 = µ3 = µ4 contra a alternativa Ha : µi ̸= µk para pelo menos um par i ̸= k. Esse problema ´e abordado na Se¸c˜ao 3. Quando a H0 desse teste ´e rejeitada, surge naturalmente a quest˜ao de comparar os efeitos dos diferentes tratamentos, para decidir por exemplo se um deles ´e signiﬁcativamente melhor que os outros. Esse tipo de problema ´e conhecido pelo nome de Compara¸c˜oes m´ultiplas e ser´a discutido na Se¸c˜ao 4. A Se¸c˜ao 1 apresenta o modelo e a nota¸c˜ao geral. Finalmente, o apˆendice contem um script na linguagem R usado para os c´alculos nos exemplos apresentados. 1 Nota¸c˜ao e modelo Consideramos I > 2 tratamentos ou popula¸c˜oes com J observa¸c˜oes em cada um (esse delineamento ´e dito balanceado; o caso que os n´umeros de observa¸c˜oes para cada trata- mento s˜ao diferentes ser´a discutido brevemente mais na frente). A j-´esima observa¸c˜ao do i-´esimo tratamento ser´a denotada por Yi,j ou yi,j. Na Tabela 1 temos, por exem- 3 4 6 8 121.01.52.02.53.03.54.0 prod1fert1234 4 6 8 12 6 8 101.01.52.02.53.03.54.0 prod1fert1234 6 8 10 5 7 9 111.01.52.02.53.03.54.0 prod1fert1234 5 7 9 11 4 6 8 121.01.52.02.53.03.54.0 prod1fert1234 4 6 8 12 4 6 8 101.01.52.02.53.03.54.0 prod1fert1234 4 6 8 10 Figura 3: Gr´aﬁco de pontos (dotplots) e de caixa (boxplots) para 5 amostras aleat´orias de tamanho 24 da distribui¸c˜ao Normal com µ e σ iguais a m´edia dos 24 valores da da Tabela 1. plo, que y2,3 = 7.2 e y3,2 = 7.5. O modelo espec´ıﬁca que, para cada tratamento i, Yi,1, Yi,2, . . . , Yi,J ´e uma amostra da distribui¸c˜ao Normal com m´edia µi e desvio padr˜ao σ, assumido igual para todos os i tratamentos. Dessa forma, as m´edias µi (i = 1, . . . , I) descrevem as m´edias dos tratamentos e ser˜ao o objeto do nosso estudo. Alternativamente podemos escrever Yi,j = µi + ϵi,j , (2) onde os erros aleat´orios ϵi,j formam uma amostra de tamanho (n I) da distribui¸c˜ao Normal com m´edia µ = 0 e desvio padr˜ao σ. Algumas vezes a equa¸c˜ao (2) ´e escrita da forma alternativa Yi,j = µ + αi + ϵi,j , (3) onde µ ´e uma m´edia geral e os parˆametros αi descrevem os efeitos dos tratamentos. Por´em, veja que essa vers˜ao do modelo permanece idˆentica se somarmos uma constante c a m´edia geral µ e subtrairmos o mesmo valor de cada efeito αi (i.´e. µ+αi ≡ (µ+c)+(αi−c) para todo c). Na literatura diz-se que os parˆametros µ, α1, . . . , αI n˜ao s˜ao identiﬁc´aveis e, por esse motivo, ´e usual acrescentar a restri¸c˜ao α1 + α2 + · · · + αI = 0 (4) na vers˜ao (3). Usualmente queremos testar a hip´otese nula que µ1 = · · · = µI contra a alternativa que µi ̸= µk para pelo menos um par (i, k). Com base no modelo (2), um estimador n˜ao-viesado para a m´edia µi ser´a a corres- pondente m´edia amostral, Y i,· = J −1 J∑ j=1 Yi,j , 4 enquanto a m´edia geral para todos os I tratamentos ´e Y ·,· = (IJ) −1 I∑ i=1 J∑ j=1 Yi,j = (I J) −1 I∑ i=1 Y i,· (a nota¸c˜ao anterior ´e muito conveniente: um “·” no lugar de um sub´ındice signiﬁca calcular a m´edia somando sobre ele e dividindo pelo correspondente n´umero de unidades). Cada uma das I amostras ou tratamentos fornece tamb´em um estimador n˜ao-viesado para σ2; S2 i = (J − 1) −1 J∑ j=1(Yi,j − Y i,·)2 . Por exemplo, na Tabela 1 temos I = 4 tipos de fertilizante, J = 6 mudas foram obser- vadas para cada tratamento, Y 2,· . = 8.42, S2 3 . = 1.15, Y ·,· . = 8.52 e assim por diante. 2 Cuidado! Por que n˜ao comparar as m´edias duas a duas? Dado que da Unidade anterior sabemos como comparar pares de m´edias, podemos nos perguntar porque n˜ao comparar cada par de m´edias. Por exemplo, no exemplo 2 temos quatro tratamentos (fertilizantes) e poder´ıamos testar cada par de m´edias poss´ıveis. Tem no total (4 2 ) = 6 pares para comparar (µ1 com µ2, µ1 com µ3, µ1 com µ4, µ2 com µ3, µ2 com µ4 e ﬁnalmente µ3 com µ4). Para i < j, chame H0;i,j a hip´otese nula que µi = µj. Suponha que para cada um dos seis pares (i, j) fazemos um teste t para testar H0;i,j ao n´ıvel de signiﬁcˆancia 100 α%, de forma que P (Rejeitar H0;i,j|µi = µj) = α. No ﬁnal rejeitar´ıamos a H0 : µ1 = µ2 = µ3 = µ4 se, e somente se, rejeitamos pelo menos uma das H0;i,j. ´E claro que gostar´ıamos de saber qual ´e o n´ıvel de signiﬁcˆancia do teste ˆonibus, isto ´e, procedendo dessa forma, qual ser´ıa a probabilidade de rejeitar H0 quando H0 ´e verdadeira. Veja que P (Rejeitar H0|H0) = P (Rejeitar pelo menos uma das H0;i,j|H0) = 1 − P (N˜ao rejeitar nenhuma das H0;i,j|H0) . Se os seis testes fossem independentes, o resultado anterior seria 1 − (1 − α)6. Por exem- plo, quando α = 0.10, o n´ıvel de signiﬁcˆancia do teste ˆonibus ser´ıa 1 − (0.90)6 . = 0.47, muito maior que o n´ıvel 0.10 usado para cada um dos seis testes individuais. O problema ´e na verdade um pouco mais complicado, pois os seis testes n˜ao s˜ao independentes. Por exemplo, para testar H0;1,2 usamos as amostras dos tratamentos 1 e 2, enquanto para tes- tar H0;1,3 usamos tamb´em a amostra do tratamento 1, o que vai causar dependˆencia dos estat´ısticos usados para esses dois testes. O m´etodo global que ser´a discutido na pr´oxima Se¸c˜ao controla a probabilidade de erro de forma a garantir que P (Rejeitar H0|H0) seja efetivamente igual ao n´ıvel de signiﬁcˆancia especiﬁcado. Somente por curiosidade, realizamos uma simula¸c˜ao para ter ideia de qual seria a taxa de rejei¸c˜ao numa situa¸c˜ao semelhante ao do Exemplo 2. Para isso, simulamos 5 M = 10, 000 vezes dados semelhantes aos da Tabela 1, com I = 4 tratamentos e J = 6 observa¸c˜oes por tratamento. As observa¸c˜oes foram todas simuladas de uma distribui¸c˜ao Normal com m´edia µ = 8.52 e desvio padr˜ao σ = (3.37)1/2, de forma que todas as I = 4 m´edias dos tratamentos s˜ao iguais. Depois, para cada instˆancia da simula¸c˜ao, comparamos os (I 2) = (4 2 ) = 6 pares de m´edias e rejeitamos H0 se pelo menos uma das seis diferen¸cas foi signiﬁcativa ao n´ıvel α = 0.10 (usamos para isso o teste t com variˆancias iguais). No ﬁnal das M = 10, 000 simula¸c˜oes veriﬁcamos que H0 foi rejeitada 35% das vezes, consideravelmente mais do que o n´ıvel de signiﬁcˆancia 10% usado para as compara¸c˜oes individuais. O c´odigo da simula¸c˜ao na linguagem R est´a no apˆendice. 3 A tabela ANOVA Vamos fazer uma decomposi¸c˜ao da variˆancia semelhante `a equa¸c˜ao (1). Para isso deﬁ- nimos (i) a soma de quadrados total corrigida pela m´edia: SQtot = I∑ i=1 J∑ j=1(Yi,j − Y ·,·)2 , (ii) a soma de quadrados explicada pelos tratamentos SQtrat = J I∑ i=1(Y i,· − Y ·,·) 2 e (iii) a soma de quadrados residual ou dos erros SQerro = I∑ i=1 J∑ j=1(Yi,j − Y i,·) 2 = (J − 1) I∑ i=1 S2 i . Essas somas recebem v´arios outros nomes. Por exemplo, a SQtrat ´e algumas vezes chamada de soma de quadrados explicada ou entre os grupos, enquanto a SQerro ´e tamb´em chamada de soma de quadrados residual ou dentro dos grupos. A identidade fundamental ´e SQtot = SQerro + SQtrat. Para prov´a-la, veja que SQtot = I∑ i=1 J∑ j=1(Yi,j − Y ·,·) 2 = I∑ i=1 J∑ j=1(Yi,j − Y i,· + Y i,· − Y ·,·)2 = I∑ i=1 J∑ j=1(Yi,j − Y i,·)2 + I∑ i=1 J∑ j=1(Y i,· − Y ·,·) 2 + 2 I∑ i=1 J∑ j=1(Yi,j − Y i,·) (Y i,· − Y ·,·) = SQerro + J I∑ i=1(Y i,· − Y ·,·)2 + 2 I∑ i=1(Y i,· − Y ·,·) J∑ j=1(Yi,j − Y i,·) = SQerro + SQtrat , (5) 6 onde temos usado que ∑J j=1(Y i,· − Y ·,·)2 = J (Y i,· − Y ·,·)2 e ∑J j=1(Yi,j − Y i,·) = J Y i,· − J Y i,· = 0. Veja que, independente da H0 ser verdadeira ou falsa (i.´e. das m´edias µi serem iguais ou diferentes), E(SQerro) = E [ I∑ i=1(J − 1) S2 i ] = (J −1) I∑ i=1 E(S2 i ) = (J −1) I∑ i=1 σ2 = I (J −1) σ2 . (6) Na terminologia da an´alise de variˆancia, a raz˜ao entre SQerro e [I (J − 1)] ´e chamada de quadrados m´edio do erro (QMerro), isto ´e, QMerro = SQerro I (J − 1) = ∑I i=1 S2 i I . A equa¸c˜ao (6) diz que QMerro ´e um estimador n˜ao-viesado para σ2, independente da H0 ser verdadeira ou falsa. Para avaliar E(SQtrat), veja do modelo (2) que Y i,· = µi + ϵi,· e Y ·,· = µ· + ϵ·,·, onde µ· = I −1 ∑I i=1 µi ≥ 0, com igualdade se, e somente se, µ1 = µ2 = · = µI . Logo, como E(ϵi,· − ϵ·,·) = 0, segue que E[SQtrat] = E [ J I∑ i=1(ϵi,· − ϵ·,· + µi − µ·)2] = J I∑ i=1 E [ (ϵi,· − ϵ·,· + µi − µ·) 2] = J { I∑ i=1 E(ϵi,· − ϵ·,·) 2 + 2 I∑ i=1(µi − µ·) E(ϵi,· − ϵ·,·) + I∑ i=1(µi − µ·) 2} = J E [ I∑ i=1(ϵi,· − ϵ·,·)2] + J I∑ i=1(µi − µ·) 2 . (7) Finalmente, para avaliar o primeiro somando no termo mais `a direita, note que ϵ1,·, . . . , ϵI,· iid ∼ Normal(0,σ2/J) e que ϵ·,· = I −1 ∑I i=1 ϵi,· ´e a m´edia “amostral” dos ϵi,·, de forma que agora (I − 1)−1 ∑I i=1(ϵi,· − ϵ·,·)2 ´e a variˆancia amostral dos ϵi,·, cujo valor esperado sabe- mos que ´e Var(ϵi,·) = σ2/J. Juntando esse resultado com a equa¸c˜ao (7), segue ﬁnalmente que E[SQtrat] = J E [ I∑ i=1(ϵi,· − ϵ·,·) 2] + J I∑ i=1(µi − µ·)2 = J (I − 1) σ2 J + J I∑ i=1(µi − µ·)2 = (I − 1) σ2 + J I∑ i=1(µi − µ·) 2    = (I − 1) σ2 quando H0 ´e verdadeira > (I − 1) σ2 quando H0 ´e falsa Dessa forma, quando a H0 ´e verdadeira, a raz˜ao entre SQtrat e (I − 1), chamada de quadrados m´edios devidos aos tratamentos (QMtrat), tamb´em estima σ2, mas quando H0 ´e falsa, o seu valor esperado ´e maior do que σ2. 7 Fonte de gl Soma de Quadrados Fobs varia¸c˜ao quadrados m´edios Tratamentos (I − 1) SQtrat = J ∑I i=1(Y i,· − Y ·,·)2 QMtrat = SQtrat I−1 QMtrat QMerro Erro I (J − 1) SQerro = ∑I i=1 ∑J j=1(Yi,j − Y i,·)2 QMerro = SQerro I (J−1) Total I J − 1 SQtot = ∑I i=1 ∑J j=1(Yi,j − Y ·,·)2 Tabela 2: Tabela de An´alise da Variˆancia ou ANOVA. Note que E(QMerro) = σ2, enquanto E(QMtrat) = σ2 + (I − 1) ∑I i=1(µi − ¯µ)2 ≥ σ2, com igualdade se, e somente se, µ1 = µ2 = · · · = µI . O argumento anterior sugere usar como estat´ıstico do teste a quantidade F = QMtrat/QMerro , no entendido que, sob H0, dever´ıamos observar valores de F perto de 1, mas quando H0 ´e falsa, esperar´ıamos valores de F signiﬁcativamente maiores que 1. Para dar um signiﬁcado preciso `a palavra signiﬁcativamente, precisamos calcular a distribui¸c˜ao do estat´ıstico F sob H0. Em cursos mais avan¸cados de estat´ıstica mostra-se que • SQerro/σ2 segue uma distribui¸c˜ao χ2 com I (J − 1) gl; • SQtrat/σ2 segue, sob H0, uma distribui¸c˜ao χ2 com (I − 1) gl e • Sob H0, SQerro e SQtrat s˜ao independentes. Dessa forma, sabemos da deﬁni¸c˜ao da distribui¸c˜ao F de Snedecor que, sob H0, F = QMtrat QMerro = 1 σ2 QMtrat/(I − 1) 1 σ2 QMerro/[I(J − 1)] ´e um quociente entre duas vari´aveis aleat´orias independentes com distribui¸c˜ao χ2 dividi- das pelos respectivos graus de liberdade e segue, portanto, uma distribui¸c˜ao F(I−1);I(J−1) e o nosso teste rejeita H0 quando Fobs > F1−α;(I−1);I(J−1). Usualmente, a informa¸c˜ao necess´aria para o c´alculo do estat´ıstico F ´e usualmente apresentada na Tabela 2, chamada Tabela da An´alise da Variˆancia ou ANOVA (por Analisys of Variance). Exemplo 2. (Continua¸c˜ao). No exemplo da Tabela 1 temos SQerro . = (6 − 1) [2.282 + 1.682 + 1.072 + 2.082] . = 67.48, SQtrat . = 6 [(8.72 − 8.52)2 + (8.42 − 8.52)2 + (6.63 − 8.52)2 + 8 (10.32 − 8.52)2] . = 41.02 e portanto SQtot . = 108.50. Os quadrados m´edios s˜ao QMtrat . = 41.02/3 . = 13.67 e QMerro . = 67.48/20 . = 3.37 e portanto Fobs . = 13.67/3.37 . = 4.05. Como o percentil 95% da distribui¸c˜ao F com 4−1 = 3 gl no numerador e 4(6−1) = 20 no denominador ´e F0.05;3,20 . = 3.10, rejeitamos a H0 que todas as m´edias s˜ao iguais. O p-valor desse teste ´e P (F3,20 > 4.053) . = 0.02 ou 2%. ´E conveniente realizar os c´alculos anteriores com alguma rotina computacional. Na linguagem R, usamos as fun¸c˜oes aov (por “Analisis of Variance”) e summary (aplicada ao resultado de aov, como em summary(aov(prod fert))) (novamente, veriﬁque o c´odigo R no apˆendice). A Tabela ANOVA produzida pelo R segue > ajuste<-aov(colheita~fert) # modelo tomate = (m´edia do trat i) + erro > summary(ajuste) # resumo do ajuste (tabela anova) Df Sum Sq Mean Sq F value Pr(>F) fert 3 41.02 13.674 4.053 0.0211 * Residuals 20 67.48 3.374 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 4 Compara¸c˜oes m´ultiplas Se o teste da Se¸c˜ao anterior resultou em rejeitar a H0, possivelmente precisamos decidir quais pares das m´edias dos tratamentos s˜ao diferentes. Como vimos na Se¸c˜ao 2, n˜ao ´e correto usar os m´etodos para comparar as m´edias de duas popula¸c˜oes discutidos na Unidade anterior, pelo menos sem realizar algum tipo de ajuste no n´ıvel de signiﬁcˆancia. Existem muitos m´etodos estat´ısticos para abordar esse problema, que ´e usualmente denominado compara¸c˜oes m´ultiplas na literatura. Aqu´ı vamos a apresentar t˜ao somente o m´etodo de Tukey ou HSD (por Honest Signiﬁcant Diﬀerences). Suponha que queremos testar somente se H0;i,j : µi = µj. Nesse caso, e lembrando que os dois tamanhos amostrais s˜ao iguais, usar´ıamos o teste t com variˆancias iguais, tobs = ¯yj,· − ¯yi,· sc;i,j √ 1 J + 1 J = ¯yj,· − ¯yi,· sc;i,j √ 2/J , (8) onde s2 c;i,j = (s2 i + s2 j )/2 ´e o estimador combinado da variˆancia. O fato de querer testar v´arias compara¸c˜oes ao mesmo tempo introduz duas modiﬁca¸c˜oes nesse estat´ıstico. Pri- meiro, como vimos na Se¸c˜ao anterior, QMerro = SQerro/[I (J − 1)] ´e um estimador para σ2 que usa as amostras de todos os I tratamentos e ele ser´a melhor do que usar s2 c;i,j baseado somente nas amostras dos tratamentos i e j. Segundo, como discutido na Se¸c˜ao 2, existe uma variabilidade inerente as m´edias ¯yi,·, ainda quando H0 ´e verdadeira, que deve ser tomada em conta. Por isso, para realizar compara¸c˜oes m´ultiplas, ao inv´es da 9 express˜ao (8), usa-se T = maxi{¯yi,·} − mini{¯yi,·} √QMerro √ 2/J . (9) Sob a H0 que todas as m´edias s˜ao iguais, T segue uma distribui¸c˜ao denominada de alcance studentizado (Studentized Range Distribution em inglˆes) com I m´edias e I (J − 1) graus de liberdade (referentes a o estimador QMerro de σ2. Na linguagem R, a fun¸c˜ao de distribui¸c˜ao acumulada dessa distribui¸c˜ao ´e acessada pela fun¸c˜ao ptukey, enquanto a sua inversa ´e qtukey. Denotaremos por Tα;m;gl o valor que deixa 100 α% de ´area `a sua direita na distribui¸c˜ao de Alcance Studentizado com m m´edias e gl graus de liberdade. Por exemplo, para obter que T0.05;4;20 . = 3.958, digitamos no R qtukey(0.95,4,20) Observa¸c˜ao. Existem diferentes tabula¸c˜oes da distribui¸c˜ao de Alcance Studentizado. Algumas usam o termo √2 no denominador e outras n˜ao. Para o c´alculo correto dos intervalos de conﬁan¸ca a seguir, ´e importante saber qual est´a sendo usada. Com base na distribui¸c˜ao de Alcance Studentizado, os intervalos de conﬁan¸ca de Tukey ou HSD para as diferen¸cas µi − µj com conﬁan¸ca simultanea de 100 (1 − α)% s˜ao dados por ¯yj,· − ¯yi,· ± Tα;I,I (J−1) √ QMerro J . (10) Para testar as hip´oteses nulas que µi = µj (1 ≤ i < j ≤ I), podemos simplesmente calcular os intervalos acima e veriﬁcar quais deles contem o ponto µj − µi = 0. No R, os intervalos de Tukey s˜ao calculados pela fun¸c˜ao TukeyHSD (cuidado, R faz distin¸c˜ao entre mai´usculas e min´usculas). Exemplo 2. (Continua¸c˜ao). Como vimos antes que rejeitamos a H0 que todas as m´edias s˜ao iguais, fazemos agora as compara¸c˜oes m´ultiplas. Para construir intervalos com 95% de conﬁan¸ca, vimos antes que T0.05;4;20 . = 3.958 e QM Eerro . = 3.374. Assim, os intervalos de conﬁan¸ca 10 v˜ao ser da forma ¯yj,· − ¯yi,· ± (3.958) √ 3.374/6 . = ¯yj,· − ¯yi,· ± 2.968 Por exemplo, para comparar as m´edias dos fertilizantes 1 e 2, o IC ´e 8.72 − 8.42 ± 2.968 . = (−2.668; 3.268) e, como cont´em o valor µ1 −µ2 = 0, n˜ao ´e poss´ıvel concluir que as m´edias dos fertilizantes 1 e 2 s˜ao diferentes. Para fazer o resto das compara¸c˜oes, ´e poss´ıvel usar a fun¸c˜ao TukeyHSD no R. Abaixo mostramos o resultado dela no exemplo. Veja que a ´unica diferen¸ca de m´edias signiﬁcativamente diferente de zero s˜ao as referentes aos fertilizantes 3 e 4. > ajuste<-aov(colheita~fert) # modelo colheita = (m´edia do trat i) + erro > TukeyHSD(ajuste,ordered=T,conf.level=0.95) # calcule ICs, m´edias ordenadas Tukey multiple comparisons of means 95% family-wise confidence level factor levels have been ordered Fit: aov(formula = colheita ~ fert) $fert 10 diff lwr upr p adj 2-3 1.783333 -1.1849103 4.751577 0.3588379 1-3 2.083333 -0.8849103 5.051577 0.2342865 4-3 3.683333 0.7150897 6.651577 0.0118130 1-2 0.300000 -2.6682436 3.268244 0.9918528 4-2 1.900000 -1.0682436 4.868244 0.3062333 4-1 1.600000 -1.3682436 4.568244 0.4510595 5 Diagn´ostico do modelo Existem basicamente dois supostos que foram feitos nas Se¸c˜oes anteriores. Primeiro, assumimos que todas as observa¸c˜oes seguem uma distribui¸c˜ao Normal. Segundo, assu- mimos que as variˆancias dentro de cada tratamento ou subpopula¸c˜ao s˜ao iguais. Nas aplica¸c˜oes, usualmente queremos checar se os dados suportam esses supostos. Apˆendice: C´odigo R ####################################### # Exemplo 1 ####################################### par(mfrow=c(2,2)) # fa¸ca uma figura com 4 gr´aficos ordenados 2x2 set.seed(999) x<-rnorm(100,0,1) # gere 100 observa¸c~oes da Normal com m´edia 0 e desvio padr~ao 1 hist(x,xlim=c(-4,4),main=’(a)’,ylab=’frequ^encia’) # fa¸ca um histograma das 100 observa¸c~oes sd(x) # calcule o desvio padr~ao da amostra mean(x) y<-rep(NA,100) y[1:50]<-x[1:50]-1 # subtraia 1 as primeiras 50 observa¸c~oes y[51:100]<-x[51:100]+1 # some 1 as ´ultimas 50 observa¸c~oes hist(y,xlim=c(-4,4),main=’(b)’,ylab=’frequ^encia’) # fa¸ca um histograma da nova amostra sd(y) mean(y) hist(y[1:50],xlim=c(-4,4),,main=’(c)’,ylab=’frequ^encia’) # fa¸ca um histograma das primeiras 50 observa¸c~oes hist(y[51:100],xlim=c(-4,4),,main=’(d)’,ylab=’frequ^encia’) # fa¸ca um histograma das ´ultimas 50 observa¸c~oes 11 mean(y[1:50]) mean(y[51:100]) sd(y[1:50]) sd(y[51:100]) 99*sd(y)^2 49*(sd(y[1:50])^2+sd(y[51:100])^2)+ 50*((mean(y[1:50])-mean(y))^2+(mean(y[51:100])-mean(y))^2) ###################################### # Exemplo 2 ##################################### I<-4 # n´umero de tratamentos J<-6 # no. de observa¸c~oes por tratamento fert<-factor(rep(1:I,times=rep(J,I))) # vari´avel qualitativa (factor) para os tratamentos colheita<-c(10.5,9.7,5.5,11.0,9.3,6.3, # produ¸c~ao de tomates 7.1,10.2,7.2,7.8,10.9,7.3, 4.7,7.5,6.5,7.7,6.5,6.9, 8.5,12.4,11.5,7.1,10.6,11.8) for(i in unique(fert)){print(mean(colheita[fert==i]))} # m´edias por tratamento for(i in unique(fert)){print(sd(colheita[fert==i]))} # dp por tratamento for(i in unique(fert)){print(sd(colheita[fert==i])^2)} # var. por tratamento sqrt((5.177667+2.837667+1.146667+4.333667)/4) # m´edia das vari^ancias ajuste<-aov(colheita~fert) # modelo tomate = (m´edia do trat i) + erro summary(ajuste) # resumo do ajuste (tabela anova) qf(0.95,3,20) # percentil 95% da F com 3 e 24 gl 1-pf(4.053,3,20) qtukey(0.95,nmeans=4,df=20) ajuste<-aov(colheita~fert) # modelo colheita = (m´edia do trat i) + erro TukeyHSD(ajuste,ordered=T,conf.level=0.95) # calcule ICs, m´edias ordenadas par(mfrow=c(1,2)) plot(colheita,fert,pch=19,col=fert,cex=1.5) # gr´aficos de pontos (boxplots) for(i in 1:4){lines(c(0,14),c(i,i),col=i,lwd=0.5)} 12 boxplot(colheita~fert,horizontal=T) # gr´aficos de caixa (boxplots) par(mfcol=c(2,5)) # gr´aficos para dados simulados for(j in 1:5){ colheita1<-rnorm(I*J,mean(colheita),sd(colheita)) plot(colheita1,fert,pch=19,col=fert,cex=1.5) for(i in 1:4){lines(c(0,14),c(i,i),col=i,lwd=0.5)} boxplot(colheita1~fert,horizontal=T) } ################################ ### Simula¸c~ao da Se¸c~ao Cuidado! ################################ M<-10000 # tamanho da simula¸c~ao alfa<-0.10 # nivel dos testes individuais mu<-mean(colheita) # mesma m´edia que dados de tomates sigma<-sqrt((5.177667+2.837667+1.146667+4.333667)/4) # mesma vari^ancia tamb´em rejeita.soma<-0 # contar o n´umero de vezes que rejeita a H_0 onibus for(m in 1:M){ # loop das simula¸c~oes colheita.sim<-rnorm(I*J,mu,sigma) # gere aleatoriamente um conjunto de dados rejeita<-0 # no final rejeita vai medir se rejeitou pelo menos uma comparacao for(i1 in 1:(I-1)){ for(i2 in (i1+1):I){ x<-colheita.sim[fert==i1] y<-colheita.sim[fert==i2] s.c<-sqrt((sd(x)^2+sd(y)^2)/2) if(abs(mean(y)-mean(x))>qt(1-alfa/2,2*J-2)*sqrt(2/J)*s.c){rejeita<-1} } } rejeita.soma<-rejeita.soma+rejeita } rejeita.soma/M 13","libVersion":"0.2.2","langs":""}